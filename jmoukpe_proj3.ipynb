{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE 5320 Neural Networks Project 3 with Paper\n",
    "#### Report (with Code)\n",
    "Josias Moukpe\\\n",
    "12/10/2022\n",
    "\n",
    "#### Introduction\n",
    "Text Generation is a branch of Natural Language Processing (NLP) that predicts the\n",
    "next most likely word given all the previous words. State of the art in Text Generation\n",
    "has recently been the domain of Language Models based on Transformers pretrained\n",
    "on large corpora of text data from various sources on the internet. These pretrained\n",
    "generative transformers are often fine-tuned on a downstream dataset for a\n",
    "downstream task of interest. This project aims to develop a generative language model\n",
    "based on a pretrained language transformer fine-tuned on our two chosen datasets:\n",
    "Merve-Poetry [1] and Rap Lyrics US [2]. We want to obtain a fine-tuned model that can\n",
    "generate original English poetry given an initial prompt and another that can generate\n",
    "original rap lyrics inspired by the styles of contemporary rappers. Both datasets contain\n",
    "English text from various authors and will be processed to extract the bags of words.\n",
    "Those words will then be converted to a designated embedding before being ingested\n",
    "by the generative model during fine-tuning. The pretrained model will be obtained from\n",
    "the Hugging Face library of generative models for English text.\n",
    "Merve Poetry contains renaissance and modern poetries from subjects such as Love,\n",
    "Nature, Mythology, and Folklore. The dataset is organized into 5 table columns: the\n",
    "poem's content, author, age, and subject type. Rap Lyrics US contains text documents\n",
    "organized by artists. Each text document includes lyrics from the corresponding artist.\n",
    "The final models will take an initial sequence of words (prompt) and generate a\n",
    "sequence from an original poem and rap song.\n",
    "\n",
    "#### Problem\n",
    "\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "\n",
    "#### Benchmarking\n",
    "\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "\n",
    "\n",
    "References\\\n",
    "[1] https://huggingface.co/datasets/merve/poetry/viewer/merve--poetry/train\\\n",
    "[2] https://github.com/fpaupier/RapLyrics-Scraper/tree/master/lyrics_US\\\n",
    "[3]https://huggingface.co/models?language=en&library=tf&pipeline_tag=text-generation&sort=downloads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remote Training Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.strings import regex_replace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForCausalLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry_path = './data/poetry/poetry.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make generator for the poetry dataset\n",
    "poetry_gen = poetry_generator(poetry_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "OPT_DROPOUT = 0.2\n",
    "OPT_ATT_DROPOUT = 0.2\n",
    "\n",
    "MAX_LEN = 768\n",
    "LAYER_DROPOUT = 0.2 \n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 8 # 48 on gradient  \n",
    "INIT_LR = 1e-5\n",
    "MAX_LR = 6e-4\n",
    "RANDOM_SEED = 42\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "NUM_TRAIN_SAMPLES = \n",
    "NUM_TEST_SAMPLES = \n",
    "NUM_VAL_SAMPLES = \n",
    "\n",
    "factor = .15 # 15%\n",
    "NUMBER_STEP_PER_EPOCH = int((NUM_TRAIN_SAMPLES // BATCH_SIZE) * factor)\n",
    "NUMBER_STEP_PER_VALIDATION = int((NUM_VAL_SAMPLES // BATCH_SIZE) * factor)\n",
    "NUMBER_STEP_PER_TEST = int((NUM_TEST_SAMPLES // BATCH_SIZE) * factor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model (on and off metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "Don't train on both dataset at the same time, might not find commonality\n",
    "During this project..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "248d42be7c44ee8282c278444327b72294a65bb1209edb41c57e3d849342db5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
