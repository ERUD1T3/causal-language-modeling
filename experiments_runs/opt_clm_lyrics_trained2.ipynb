{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE 5320 Neural Networks Project 3 with Paper\n",
    "#### Report (with Code)\n",
    "Josias Moukpe\\\n",
    "12/10/2022\n",
    "\n",
    "#### Introduction\n",
    "Text Generation is a branch of Natural Language Processing (NLP) that predicts the\n",
    "next most likely word given all the previous words. State of the art in Text Generation\n",
    "has recently been the domain of Language Models based on Transformers pretrained\n",
    "on large corpora of text data from various sources on the internet. These pretrained\n",
    "generative transformers are often fine-tuned on a downstream dataset for a\n",
    "downstream task of interest. This project aims to develop a generative language model\n",
    "based on a pretrained language transformer fine-tuned on our two chosen datasets:\n",
    "Merve-Poetry [1] and Rap Lyrics US [2]. We want to obtain a fine-tuned model that can\n",
    "generate original English rapperry given an initial prompt and another that can generate\n",
    "original rap lyrics inspired by the styles of contemporary rappers. Both datasets contain\n",
    "English text from various authors and will be processed to extract the bags of words.\n",
    "Those words will then be converted to a designated embedding before being ingested\n",
    "by the generative model during fine-tuning. The pretrained model will be obtained from\n",
    "the Hugging Face library of generative models for English text.\n",
    "Merve Poetry contains renaissance and modern rapperries from subjects such as Love,\n",
    "Nature, Mythology, and Folklore. The dataset is organized into 5 table columns: the\n",
    "lyric's content, author, age, and subject type. Rap Lyrics US contains text documents\n",
    "organized by artists. Each text document includes lyrics from the corresponding artist.\n",
    "The final models will take an initial sequence of words (prompt) and generate a\n",
    "sequence from an original lyric and rap song.\n",
    "\n",
    "#### Problem\n",
    "\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "\n",
    "#### Benchmarking\n",
    "\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "\n",
    "\n",
    "References\\\n",
    "[1] https://huggingface.co/datasets/merve/rapperry/viewer/merve--rapperry/train\\\n",
    "[2] https://github.com/fpaupier/RapLyrics-Scraper/tree/master/lyrics_US\\\n",
    "[3]https://huggingface.co/models?language=en&library=tf&pipeline_tag=text-generation&sort=downloads\\\n",
    "[4] https://www.projectpro.io/recipes/what-is-causal-language-modeling-transformers\\\n",
    "[5] https://towardsdatascience.com/understanding-masked-language-models-mlm-and-causal-language-models-clm-in-nlp-194c15f56a5\\\n",
    "[6] https://github.com/christianversloot/machine-learning-articles/blob/main/easy-causal-language-modeling-with-machine-learning-and-huggingface-transformers.md\\\n",
    "[7] https://heartbeat.comet.ml/causal-language-modeling-with-gpt-d92c9cfe2d2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remote Training Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:47.420853Z",
     "iopub.status.busy": "2022-12-13T05:18:47.420497Z",
     "iopub.status.idle": "2022-12-13T05:18:54.478811Z",
     "shell.execute_reply": "2022-12-13T05:18:54.478004Z",
     "shell.execute_reply.started": "2022-12-13T05:18:47.420785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.9/dist-packages (0.19.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.20.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (18.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow_addons\n",
    "%pip install transformers\n",
    "%pip install datasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:54.480539Z",
     "iopub.status.busy": "2022-12-13T05:18:54.480306Z",
     "iopub.status.idle": "2022-12-13T05:18:59.146461Z",
     "shell.execute_reply": "2022-12-13T05:18:59.145763Z",
     "shell.execute_reply.started": "2022-12-13T05:18:54.480515Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.optimizers import CyclicalLearningRate\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.strings import regex_replace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFOPTForCausalLM, TFAutoModelForCausalLM\n",
    "from transformers import AutoConfig\n",
    "from transformers import tf_top_k_top_p_filtering\n",
    "from transformers import DefaultDataCollator\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.148069Z",
     "iopub.status.busy": "2022-12-13T05:18:59.147471Z",
     "iopub.status.idle": "2022-12-13T05:18:59.155351Z",
     "shell.execute_reply": "2022-12-13T05:18:59.154749Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.148042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.157250Z",
     "iopub.status.busy": "2022-12-13T05:18:59.157013Z",
     "iopub.status.idle": "2022-12-13T05:18:59.164196Z",
     "shell.execute_reply": "2022-12-13T05:18:59.163586Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.157229Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = 'facebook/opt-350m' #TODO: try larger facebook/opt-350m, facebook/opt-1.3b\n",
    "# consts\n",
    "OPT_DROPOUT = 0.1\n",
    "OPT_ATT_DROPOUT = 0.1\n",
    "LAYER_DROPOUT = 0.1\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "MAX_LEN = 2048\n",
    "CONTEXT_LEN = 256\n",
    "BATCH_SIZE = 8 # 48 on gradient  \n",
    "INIT_LR = 9e-9\n",
    "MAX_LR = 1e-7\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.95\n",
    "WEIGHT_DECAY = 0.01 # for transformers\n",
    "W_INIT_MEAN = 0.0\n",
    "W_INIT_STDDEV = 0.006\n",
    "B_INIT_VALUE = 0.0\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "NUM_EPOCHS = 50\n",
    "TOP_K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.165182Z",
     "iopub.status.busy": "2022-12-13T05:18:59.164954Z",
     "iopub.status.idle": "2022-12-13T05:18:59.168820Z",
     "shell.execute_reply": "2022-12-13T05:18:59.168228Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.165164Z"
    }
   },
   "outputs": [],
   "source": [
    "# lyrics dataset\n",
    "LYRICS_CARDINALITY = 10255\n",
    "LYRICS_MAX_LEN = 2943\n",
    "LYRICS_TRAIN_SAMPLES = 8242\n",
    "LYRICS_VAL_SAMPLES = 1017\n",
    "LYRICS_TEST_SAMPLES = 996\n",
    "\n",
    "STEP_PER_EPOCH = LYRICS_TRAIN_SAMPLES // BATCH_SIZE\n",
    "STEP_PER_VAL = LYRICS_VAL_SAMPLES // BATCH_SIZE\n",
    "STEP_PER_TEST = LYRICS_TEST_SAMPLES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.169773Z",
     "iopub.status.busy": "2022-12-13T05:18:59.169566Z",
     "iopub.status.idle": "2022-12-13T05:18:59.173564Z",
     "shell.execute_reply": "2022-12-13T05:18:59.172958Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.169750Z"
    }
   },
   "outputs": [],
   "source": [
    "# define cyclic learning rate\n",
    "CLR = CyclicalLearningRate(\n",
    "    initial_learning_rate=INIT_LR,\n",
    "    maximal_learning_rate=MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.** (x - 1)),\n",
    "    step_size=2 * STEP_PER_EPOCH,\n",
    "    scale_mode='cycle'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.174409Z",
     "iopub.status.busy": "2022-12-13T05:18:59.174234Z",
     "iopub.status.idle": "2022-12-13T05:18:59.177868Z",
     "shell.execute_reply": "2022-12-13T05:18:59.177351Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.174392Z"
    }
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "OPTIM = AdamW(\n",
    "    learning_rate=2e-5,# for transformers #CLR,\n",
    "    beta_1=BETA1,\n",
    "    beta_2=BETA2,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    clipnorm=CLIP_NORM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.178788Z",
     "iopub.status.busy": "2022-12-13T05:18:59.178610Z",
     "iopub.status.idle": "2022-12-13T05:18:59.181605Z",
     "shell.execute_reply": "2022-12-13T05:18:59.181090Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.178772Z"
    }
   },
   "outputs": [],
   "source": [
    "initializer = TruncatedNormal(\n",
    "    mean=W_INIT_MEAN,\n",
    "    stddev=W_INIT_STDDEV,\n",
    "    seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.182505Z",
     "iopub.status.busy": "2022-12-13T05:18:59.182337Z",
     "iopub.status.idle": "2022-12-13T05:18:59.185984Z",
     "shell.execute_reply": "2022-12-13T05:18:59.185491Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.182488Z"
    }
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [\n",
    "    # EarlyStopping(\n",
    "    #     monitor='val_accuracy', \n",
    "    #     patience=6,\n",
    "    #     restore_best_weights=True\n",
    "    # ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='./models/rapper/rapper',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.9, \n",
    "        patience=6, \n",
    "        verbose=1, \n",
    "        mode='min',\n",
    "        min_lr=0\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.188496Z",
     "iopub.status.busy": "2022-12-13T05:18:59.188314Z",
     "iopub.status.idle": "2022-12-13T05:18:59.191436Z",
     "shell.execute_reply": "2022-12-13T05:18:59.190888Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.188479Z"
    }
   },
   "outputs": [],
   "source": [
    "lyrics_path = './data/lyrics.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.192227Z",
     "iopub.status.busy": "2022-12-13T05:18:59.192060Z",
     "iopub.status.idle": "2022-12-13T05:18:59.194825Z",
     "shell.execute_reply": "2022-12-13T05:18:59.194318Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.192211Z"
    }
   },
   "outputs": [],
   "source": [
    "# # use a generator to read the json file\n",
    "# def parse(dataset_path):\n",
    "#     '''\n",
    "#         This function reads the json file and returns a generator\n",
    "#     '''\n",
    "#     dataf = open(dataset_path, 'r', encoding='utf-8')\n",
    "#     for line in dataf:\n",
    "#         # get the text and stars\n",
    "#         yield json.loads(line)['author'], json.loads(line)['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.195550Z",
     "iopub.status.busy": "2022-12-13T05:18:59.195385Z",
     "iopub.status.idle": "2022-12-13T05:18:59.199264Z",
     "shell.execute_reply": "2022-12-13T05:18:59.198790Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.195534Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_stats(dataset, plotting=True):\n",
    "#     '''\n",
    "#         This function plots the number of authors and content,\n",
    "#         the average number of words per content and the average\n",
    "#         number of characters per content\n",
    "\n",
    "#         Parameters:\n",
    "#             dataset_path (str): path to the dataset or generator\n",
    "#             plotting (bool): if True, it plots the number of contents\n",
    "#     '''\n",
    "\n",
    "\n",
    "#     # check if the dataset is a generator or a path\n",
    "#     if isinstance(dataset, str):\n",
    "#         data_gen = parse(dataset)\n",
    "#     else:\n",
    "#         data_gen = dataset\n",
    "\n",
    "#     authors = []\n",
    "#     contents = []\n",
    "#     for author, content in data_gen:\n",
    "#         authors.append(author)\n",
    "#         contents.append(content)\n",
    "        \n",
    "#     # number of authors\n",
    "#     print('Number of authors: ', len(set(authors)))\n",
    "\n",
    "#     # number of contents\n",
    "#     print('Number of contents: ', len(contents))\n",
    "\n",
    "#     # average number of words per content\n",
    "#     print('Average number of words per content: ', np.mean([len(content.split()) for content in contents]))\n",
    "\n",
    "#     # longest number of words per content\n",
    "#     print('Longest number of words per content: ', np.max([len(content.split()) for content in contents]))\n",
    "\n",
    "#     # shortest number of words per content\n",
    "#     print('Shortest number of words per content: ', np.min([len(content.split()) for content in contents]))\n",
    "\n",
    "#     # for every content, count the number of characters\n",
    "#     print('Average number of characters per content: ', np.mean([len(content) for content in contents]))\n",
    "\n",
    "#     if plotting:\n",
    "#         # for every author, count the number of contents\n",
    "#         authors_count = {}\n",
    "#         for author in authors:\n",
    "#             if author in authors_count:\n",
    "#                 authors_count[author] += 1\n",
    "#             else:\n",
    "#                 authors_count[author] = 1\n",
    "\n",
    "#         # plot the number of contents per author\n",
    "#         plt.figure(figsize=(20, 10))\n",
    "#         plt.bar(authors_count.keys(), authors_count.values())\n",
    "#         plt.xticks(rotation=90)\n",
    "#         plt.title('Number of contents per author')\n",
    "#         plt.xlabel('Author')\n",
    "#         plt.ylabel('Number of contents')\n",
    "#         plt.show()\n",
    "\n",
    "#         # for every content, count the number of words\n",
    "#         contents_count = {}\n",
    "#         for content in contents:\n",
    "#             if len(content.split()) in contents_count:\n",
    "#                 contents_count[len(content.split())] += 1\n",
    "#             else:\n",
    "#                 contents_count[len(content.split())] = 1\n",
    "\n",
    "#         # plot the number of contents per number of words\n",
    "#         plt.figure(figsize=(20, 10))\n",
    "#         plt.bar(contents_count.keys(), contents_count.values())\n",
    "#         plt.xticks(rotation=90)\n",
    "#         plt.title('Number of contents per number of words')\n",
    "#         plt.xlabel('Number of words')\n",
    "#         plt.ylabel('Number of contents')\n",
    "#         plt.show()\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.200004Z",
     "iopub.status.busy": "2022-12-13T05:18:59.199833Z",
     "iopub.status.idle": "2022-12-13T05:18:59.203357Z",
     "shell.execute_reply": "2022-12-13T05:18:59.202454Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.199988Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot the stats for the lyrics dataset\n",
    "# plot_stats(lyrics_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.204690Z",
     "iopub.status.busy": "2022-12-13T05:18:59.204417Z",
     "iopub.status.idle": "2022-12-13T05:18:59.208274Z",
     "shell.execute_reply": "2022-12-13T05:18:59.207646Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.204662Z"
    }
   },
   "outputs": [],
   "source": [
    "# # read path file write to a json file\n",
    "# def split_dataset(name, og_path, split=[.8, .1, .1]):\n",
    "#     '''\n",
    "#         read a json file and split it into train, test, and validation\n",
    "#         files according to the split parameter\n",
    "#     '''\n",
    "#     # get directory path\n",
    "#     dir_path = '/'.join(og_path.split('/')[:-1])\n",
    "#     # get the generator\n",
    "#     data = parse(og_path)\n",
    "#     # loop through the generator\n",
    "#     for author, content in data:\n",
    "#         # generate a random number between 0 and 1\n",
    "#         r = np.random.rand()\n",
    "#         # if the random number is less than the first split\n",
    "#         if r < split[0]:\n",
    "#             # write to the train file\n",
    "#             with open(dir_path + f'/{name}_train.json', 'a') as f:\n",
    "#                 f.write(json.dumps({'author': author, 'content': content}))\n",
    "#                 f.write('\\n')\n",
    "#         # if the random number is less than the first split plus the second split\n",
    "#         elif r < split[0] + split[1]:\n",
    "#             # write to the validation file\n",
    "#             with open(dir_path + f'/{name}_val.json', 'a') as f:\n",
    "#                 f.write(json.dumps({'author': author, 'content': content}))\n",
    "#                 f.write('\\n')\n",
    "#         # if the random number is less than the first split plus the second split plus the third split\n",
    "#         else:\n",
    "#              # write to the test file\n",
    "#             with open(dir_path + f'/{name}_test.json', 'a') as f:\n",
    "#                 f.write(json.dumps({'author': author, 'content': content}))\n",
    "#                 f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.209086Z",
     "iopub.status.busy": "2022-12-13T05:18:59.208872Z",
     "iopub.status.idle": "2022-12-13T05:18:59.211932Z",
     "shell.execute_reply": "2022-12-13T05:18:59.211418Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.209066Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the lyrics dataset\n",
    "# split_dataset('lyrics', lyrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.212776Z",
     "iopub.status.busy": "2022-12-13T05:18:59.212601Z",
     "iopub.status.idle": "2022-12-13T05:18:59.215914Z",
     "shell.execute_reply": "2022-12-13T05:18:59.215262Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.212760Z"
    }
   },
   "outputs": [],
   "source": [
    "# # read the train, test, and validation files\n",
    "# def read_dataset(name, path):\n",
    "#     '''\n",
    "#         read the train, test, and validation files\n",
    "#         Input:\n",
    "#             name: the name of the dataset\n",
    "#             path: the path to the dataset\n",
    "#         Output:\n",
    "#             train_ds: the train dataset generator\n",
    "#             val_ds: the validation dataset generator\n",
    "#             test_ds: the test dataset generator\n",
    "#     '''\n",
    "#     # read the train file\n",
    "#     train_path = f\"./data/{name}_train.json\"\n",
    "#     validation_path = f\"./data/{name}_val.json\"\n",
    "#     test_path = f\"./data/{name}_test.json\"\n",
    "\n",
    "#     train_ds = parse(train_path)\n",
    "#     val_ds = parse(validation_path)\n",
    "#     test_ds = parse(test_path)\n",
    "\n",
    "#     return train_ds, val_ds, test_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.216886Z",
     "iopub.status.busy": "2022-12-13T05:18:59.216676Z",
     "iopub.status.idle": "2022-12-13T05:18:59.220218Z",
     "shell.execute_reply": "2022-12-13T05:18:59.219580Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.216864Z"
    }
   },
   "outputs": [],
   "source": [
    "# # read the lyrics dataset\n",
    "# lyrics_train_ds, lyrics_val_ds, lyrics_test_ds = read_dataset('lyrics', lyrics_path)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.221278Z",
     "iopub.status.busy": "2022-12-13T05:18:59.221087Z",
     "iopub.status.idle": "2022-12-13T05:18:59.224165Z",
     "shell.execute_reply": "2022-12-13T05:18:59.223539Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.221262Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # the stats for the lyrics dataset\n",
    "# print('Trainig set')\n",
    "# plot_stats(lyrics_train_ds, plotting=False)\n",
    "# print('Validation set')\n",
    "# plot_stats(lyrics_val_ds, plotting=False)\n",
    "# print('Test set')\n",
    "# plot_stats(lyrics_test_ds, plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.225071Z",
     "iopub.status.busy": "2022-12-13T05:18:59.224873Z",
     "iopub.status.idle": "2022-12-13T05:18:59.228290Z",
     "shell.execute_reply": "2022-12-13T05:18:59.227668Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.225054Z"
    }
   },
   "outputs": [],
   "source": [
    "# # read the lyrics dataset\n",
    "# lyrics_train_ds, lyrics_val_ds, lyrics_test_ds = read_dataset('lyrics', lyrics_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.229141Z",
     "iopub.status.busy": "2022-12-13T05:18:59.228954Z",
     "iopub.status.idle": "2022-12-13T05:18:59.231696Z",
     "shell.execute_reply": "2022-12-13T05:18:59.231216Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.229124Z"
    }
   },
   "outputs": [],
   "source": [
    "# # get an example from the train dataset\n",
    "# author, content = next(lyrics_train_ds)\n",
    "# print(f'Training Example: {author}, {content}', end='\\n\\n')\n",
    "# # get an example from the validation dataset\n",
    "# author, content = next(lyrics_val_ds)\n",
    "# print(f'Validation Example: {author}, {content}', end='\\n\\n')\n",
    "# # get an example from the test dataset\n",
    "# author, content = next(lyrics_test_ds)\n",
    "# print(f'Test Example: {author}, {content}', end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.232505Z",
     "iopub.status.busy": "2022-12-13T05:18:59.232338Z",
     "iopub.status.idle": "2022-12-13T05:18:59.766784Z",
     "shell.execute_reply": "2022-12-13T05:18:59.765962Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.232489Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer\n",
    "Tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.768024Z",
     "iopub.status.busy": "2022-12-13T05:18:59.767818Z",
     "iopub.status.idle": "2022-12-13T05:18:59.772075Z",
     "shell.execute_reply": "2022-12-13T05:18:59.771386Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.768006Z"
    }
   },
   "outputs": [],
   "source": [
    "# run the tokenizer on the text\n",
    "def tokenize_fn(examples, tokenizer=Tokenizer):\n",
    "    '''\n",
    "        This function tokenizes the text\n",
    "        - Input:\n",
    "            - examples: the text\n",
    "            - tokenizer: the tokenizer\n",
    "        - Output:\n",
    "            - the tokenized text\n",
    "    '''\n",
    "\n",
    "    return tokenizer(examples['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.773150Z",
     "iopub.status.busy": "2022-12-13T05:18:59.772882Z",
     "iopub.status.idle": "2022-12-13T05:18:59.781031Z",
     "shell.execute_reply": "2022-12-13T05:18:59.780197Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.773128Z"
    }
   },
   "outputs": [],
   "source": [
    "# group text \n",
    "def group_texts(examples, context_len=CONTEXT_LEN):\n",
    "    '''\n",
    "        This function groups the texts\n",
    "        - Input:\n",
    "            - texts: the texts to group\n",
    "        - Output:\n",
    "            - grouped_texts: the grouped texts\n",
    "    '''\n",
    "    # concatenate all the texts\n",
    "    concatenated_examples = {\n",
    "        k: sum(examples[k], []) for k in examples.keys()\n",
    "    }\n",
    "    # get the total length of the texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # get the block size\n",
    "    block_size = context_len\n",
    "    # truncate the texts remainder and get new total length\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # split the texts into chunnks of max length\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result['labels'] = result['input_ids'].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.782234Z",
     "iopub.status.busy": "2022-12-13T05:18:59.782000Z",
     "iopub.status.idle": "2022-12-13T05:18:59.810212Z",
     "shell.execute_reply": "2022-12-13T05:18:59.809509Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.782212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3682e11ab0060996\n",
      "Found cached dataset generator (/root/.cache/huggingface/datasets/generator/default-3682e11ab0060996/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "def lyrics_train_gen():\n",
    "    '''\n",
    "        This function reads the json file and returns a generator\n",
    "    '''\n",
    "    dataset_path = f\"./data/lyrics_train.json\"\n",
    "    dataf = open(dataset_path, 'r', encoding='utf-8')\n",
    "    for line in dataf:\n",
    "        # get the text and stars\n",
    "        yield {'text': str(json.loads(line)['content'])}\n",
    "\n",
    "raw_train_ds = Dataset.from_generator(lyrics_train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.811201Z",
     "iopub.status.busy": "2022-12-13T05:18:59.810997Z",
     "iopub.status.idle": "2022-12-13T05:18:59.819798Z",
     "shell.execute_reply": "2022-12-13T05:18:59.819264Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.811182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d7ceff16a19f7445\n",
      "Found cached dataset generator (/root/.cache/huggingface/datasets/generator/default-d7ceff16a19f7445/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "def lyrics_val_gen():\n",
    "    '''\n",
    "        This function reads the json file and returns a generator\n",
    "    '''\n",
    "    dataset_path = f\"./data/lyrics_val.json\"\n",
    "    dataf = open(dataset_path, 'r', encoding='utf-8')\n",
    "    for line in dataf:\n",
    "        # get the text and stars\n",
    "        yield {'text':str(json.loads(line)['content'])}\n",
    "\n",
    "raw_val_ds = Dataset.from_generator(lyrics_val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.820758Z",
     "iopub.status.busy": "2022-12-13T05:18:59.820579Z",
     "iopub.status.idle": "2022-12-13T05:18:59.829011Z",
     "shell.execute_reply": "2022-12-13T05:18:59.828422Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.820739Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6c1d804aa242cf2f\n",
      "Found cached dataset generator (/root/.cache/huggingface/datasets/generator/default-6c1d804aa242cf2f/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "def lyrics_test_gen():\n",
    "    '''\n",
    "        This function reads the json file and returns a generator\n",
    "    '''\n",
    "    dataset_path = f\"./data/lyrics_test.json\"\n",
    "    dataf = open(dataset_path, 'r', encoding='utf-8')\n",
    "    for line in dataf:\n",
    "        # get the text and stars\n",
    "        yield {'text':str(json.loads(line)['content'])}\n",
    "\n",
    "raw_test_ds = Dataset.from_generator(lyrics_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.829887Z",
     "iopub.status.busy": "2022-12-13T05:18:59.829706Z",
     "iopub.status.idle": "2022-12-13T05:18:59.833529Z",
     "shell.execute_reply": "2022-12-13T05:18:59.832922Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.829869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 8242\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 996\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# make a dataset dict\n",
    "lyric_datasets = DatasetDict({\n",
    "    'train': raw_train_ds,\n",
    "    'validation': raw_val_ds,\n",
    "    'test': raw_test_ds\n",
    "})\n",
    "print(lyric_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:18:59.837455Z",
     "iopub.status.busy": "2022-12-13T05:18:59.837208Z",
     "iopub.status.idle": "2022-12-13T05:19:21.695433Z",
     "shell.execute_reply": "2022-12-13T05:19:21.694584Z",
     "shell.execute_reply.started": "2022-12-13T05:18:59.837433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-3682e11ab0060996/0.0.0/cache-ad48aafcebf40a6c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-3682e11ab0060996/0.0.0/cache-db8cea2f45f16c97.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-3682e11ab0060996/0.0.0/cache-bc87c2d9757c044b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-3682e11ab0060996/0.0.0/cache-fb361c2f1ffddb33.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-d7ceff16a19f7445/0.0.0/cache-57fb5f3bf2bf987b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-d7ceff16a19f7445/0.0.0/cache-b83cd1960203b388.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-d7ceff16a19f7445/0.0.0/cache-d00e46ad004300b7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-d7ceff16a19f7445/0.0.0/cache-b65d9b2513a90a8f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-6c1d804aa242cf2f/0.0.0/cache-acc56dbb51d546cf.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-6c1d804aa242cf2f/0.0.0/cache-1b083a1574b2eab7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-6c1d804aa242cf2f/0.0.0/cache-836dbafe9dc26e74.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-6c1d804aa242cf2f/0.0.0/cache-86a2854db761e8eb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e797d3e0dafb4613a4f228a74343b6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211657dc54954ca497a2fc6d8e2d068e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f5aa460d5a4fc5ab6813da2eaba437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90af6dbd4968449db07cd90b8f7039d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf9e780ca35461aa6f63b80292089da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a65006d185a4cb7b212952b7a89b83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919679a5f69e4abe8641804bfddc9a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82586c86f05545409526aac7572e42d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e1251a6e984180a30889f9e99a8326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f85f2638b9144bab663308b39a29c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba130f6931e4e14b6f0fe6eef01f948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494d0327a6f24b639c23ec0b7b159272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the lyrics dataset\n",
    "tokenized_lyrics_datasets = lyric_datasets.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=['text'])\n",
    "\n",
    "lyric_lm_ds = tokenized_lyrics_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:19:21.696892Z",
     "iopub.status.busy": "2022-12-13T05:19:21.696660Z",
     "iopub.status.idle": "2022-12-13T05:19:22.494063Z",
     "shell.execute_reply": "2022-12-13T05:19:22.493416Z",
     "shell.execute_reply.started": "2022-12-13T05:19:21.696872Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors='tf')\n",
    "train_set = lyric_lm_ds['train'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'labels'],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,)\n",
    "val_set = lyric_lm_ds['validation'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'labels'],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,)\n",
    "test_set = lyric_lm_ds['test'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'labels'],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:19:22.495271Z",
     "iopub.status.busy": "2022-12-13T05:19:22.495064Z",
     "iopub.status.idle": "2022-12-13T05:19:25.929803Z",
     "shell.execute_reply": "2022-12-13T05:19:25.929084Z",
     "shell.execute_reply.started": "2022-12-13T05:19:22.495252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFOPTForCausalLM.\n",
      "\n",
      "All the layers of TFOPTForCausalLM were initialized from the model checkpoint at facebook/opt-350m.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOPTForCausalLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# configure gpu for sequence classification\n",
    "# load the model\n",
    "rapper_model = TFAutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:19:25.931010Z",
     "iopub.status.busy": "2022-12-13T05:19:25.930804Z",
     "iopub.status.idle": "2022-12-13T05:19:25.958258Z",
     "shell.execute_reply": "2022-12-13T05:19:25.957541Z",
     "shell.execute_reply.started": "2022-12-13T05:19:25.930990Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfopt_for_causal_lm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFOPTMainLayer)      multiple                  331196416 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331,196,416\n",
      "Trainable params: 331,196,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rapper_model.compile(\n",
    "    optimizer=OPTIM,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# print the model summary\n",
    "rapper_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:19:25.959691Z",
     "iopub.status.busy": "2022-12-13T05:19:25.959214Z",
     "iopub.status.idle": "2022-12-13T05:19:25.963656Z",
     "shell.execute_reply": "2022-12-13T05:19:25.962641Z",
     "shell.execute_reply.started": "2022-12-13T05:19:25.959670Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model, model_path):\n",
    "    '''\n",
    "        This function loads a model\n",
    "        input:\n",
    "            - model_path: the model path\n",
    "        output:\n",
    "            - model: the model\n",
    "    '''\n",
    "    # load the model from tf format\n",
    "    model.load_weights(model_path)\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:19:25.965070Z",
     "iopub.status.busy": "2022-12-13T05:19:25.964523Z",
     "iopub.status.idle": "2022-12-13T05:19:25.967690Z",
     "shell.execute_reply": "2022-12-13T05:19:25.966933Z",
     "shell.execute_reply.started": "2022-12-13T05:19:25.965049Z"
    }
   },
   "outputs": [],
   "source": [
    "# # load the model\n",
    "# model_path = f\"./models/rapper/rapper\"\n",
    "# rapper_model = load_model(rapper_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:19:25.968766Z",
     "iopub.status.busy": "2022-12-13T05:19:25.968584Z",
     "iopub.status.idle": "2022-12-13T05:32:13.438430Z",
     "shell.execute_reply": "2022-12-13T05:32:13.437713Z",
     "shell.execute_reply.started": "2022-12-13T05:19:25.968749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "684/684 [==============================] - ETA: 0s - loss: 9.8554 - accuracy: 0.0558\n",
      "Epoch 1: val_loss improved from inf to 10.81429, saving model to ./models/rapper/rapper\n",
      "684/684 [==============================] - 410s 549ms/step - loss: 9.8554 - accuracy: 0.0558 - val_loss: 10.8143 - val_accuracy: 0.0801 - lr: 2.0000e-05\n",
      "Epoch 2/2\n",
      "684/684 [==============================] - ETA: 0s - loss: 10.8161 - accuracy: 0.0795\n",
      "Epoch 2: val_loss did not improve from 10.81429\n",
      "684/684 [==============================] - 357s 522ms/step - loss: 10.8161 - accuracy: 0.0795 - val_loss: 10.8162 - val_accuracy: 0.0801 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "\n",
    "# train the model\n",
    "history = rapper_model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # steps_per_epoch=STEP_PER_EPOCH,\n",
    "    # validation_steps=STEP_PER_VAL,\n",
    "    callbacks=CALLBACKS,\n",
    "    verbose=1\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:32:13.439582Z",
     "iopub.status.busy": "2022-12-13T05:32:13.439383Z",
     "iopub.status.idle": "2022-12-13T05:32:13.444414Z",
     "shell.execute_reply": "2022-12-13T05:32:13.443496Z",
     "shell.execute_reply.started": "2022-12-13T05:32:13.439564Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "def plot_results(history, epochs=NUM_EPOCHS):\n",
    "    '''\n",
    "        This function plots the training history\n",
    "        input:\n",
    "            - history: the training history\n",
    "        output:\n",
    "            - None\n",
    "    '''\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), history['loss'], label = 'train_loss')\n",
    "    plt.plot(np.arange(0, epochs), history['val_loss'], label = 'val_loss')\n",
    "    # plt.plot(np.arange(0, epochs), history['accuracy'], label = 'train_acc')\n",
    "    # plt.plot(np.arange(0, epochs), history['val_accuracy'], label = 'val_acc')\n",
    "        \n",
    "    # add labels and legend\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:32:13.445973Z",
     "iopub.status.busy": "2022-12-13T05:32:13.445451Z",
     "iopub.status.idle": "2022-12-13T05:32:13.571808Z",
     "shell.execute_reply": "2022-12-13T05:32:13.571203Z",
     "shell.execute_reply.started": "2022-12-13T05:32:13.445945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training history\n",
    "plot_results(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:32:13.572796Z",
     "iopub.status.busy": "2022-12-13T05:32:13.572587Z",
     "iopub.status.idle": "2022-12-13T05:32:13.576867Z",
     "shell.execute_reply": "2022-12-13T05:32:13.575631Z",
     "shell.execute_reply.started": "2022-12-13T05:32:13.572775Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_path = f\"./models/rapper/rapper\"\n",
    "# rapper_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model (on and off metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:32:13.578053Z",
     "iopub.status.busy": "2022-12-13T05:32:13.577832Z",
     "iopub.status.idle": "2022-12-13T05:32:13.581705Z",
     "shell.execute_reply": "2022-12-13T05:32:13.580851Z",
     "shell.execute_reply.started": "2022-12-13T05:32:13.578033Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model, model_path):\n",
    "    '''\n",
    "        This function loads a model\n",
    "        input:\n",
    "            - model_path: the model path\n",
    "        output:\n",
    "            - model: the model\n",
    "    '''\n",
    "    # load the model from tf format\n",
    "    model.load_weights(model_path)\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:32:13.582569Z",
     "iopub.status.busy": "2022-12-13T05:32:13.582368Z",
     "iopub.status.idle": "2022-12-13T05:32:23.488339Z",
     "shell.execute_reply": "2022-12-13T05:32:23.487549Z",
     "shell.execute_reply.started": "2022-12-13T05:32:13.582550Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_path = f\"./models/rapper/rapper\"\n",
    "rapper_model = load_model(rapper_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:32:23.489854Z",
     "iopub.status.busy": "2022-12-13T05:32:23.489617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 16s 192ms/step - loss: 10.8143 - accuracy: 0.0797\n",
      "Loss: 10.814271926879883, Accuracy: 0.079668790102005\n",
      "Perplexity: 49725.4375\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = rapper_model.evaluate(test_set, batch_size=BATCH_SIZE, verbose=1)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "# compute the perplexity\n",
    "perplexity = tf.math.exp(loss).numpy()\n",
    "print(f'Perplexity: {perplexity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:33:53.483530Z",
     "iopub.status.busy": "2022-12-13T05:33:53.482836Z",
     "iopub.status.idle": "2022-12-13T05:33:53.487776Z",
     "shell.execute_reply": "2022-12-13T05:33:53.487135Z",
     "shell.execute_reply.started": "2022-12-13T05:33:53.483504Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(model, text, tokenizer=Tokenizer, min_words=5, greedy=False):\n",
    "    '''\n",
    "        This function generates text greedily by top predictions\n",
    "        input:\n",
    "            - model: the model\n",
    "            - text: the text to generate from\n",
    "            - min_words: the minimum number of words to generate\n",
    "            - greedy: whether to use greedy or not\n",
    "        output:\n",
    "            - generated_text: the generated text\n",
    "    '''\n",
    "\n",
    "    # print the text\n",
    "    # print(f'Input text: {text}')\n",
    "    # tokenize the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='tf')\n",
    "    # pass the input ids to the model\n",
    "    output = model.generate(input_ids, min_length=min_words, max_length=256, top_k=50, top_p=0.95, do_sample=not greedy)\n",
    "    # decode the output\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    # print the generated text\n",
    "    print(f'Generated text: {generated_text}')\n",
    "    # return the generated text\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T05:34:47.227079Z",
     "iopub.status.busy": "2022-12-13T05:34:47.226452Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate text\n",
    "text = \"No matter what you say or what you do\\nWhen I'm alone, I'd rather be with you\\nFuck these other niggas\\nI'll be right by your side till 3005, hold \"\n",
    "generate_text(rapper_model, text, Tokenizer, greedy=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b2dfa36097f9487526901540832d55814665bd7ac5a80e862828915e7a7a9f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
